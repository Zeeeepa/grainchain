"""
Integration tests for the Modal provider.

These tests require actual Modal credentials and will make real API calls.
Set MODAL_TOKEN_ID and MODAL_TOKEN_SECRET environment variables to run these tests.
"""

import os
import pytest

from grainchain import Sandbox, SandboxConfig
from grainchain.core.exceptions import AuthenticationError, ProviderError
from grainchain.core.interfaces import ExecutionResult, FileInfo
from grainchain.providers.modal import ModalProvider


@pytest.mark.integration
@pytest.mark.modal
class TestModalProviderIntegration:
    """Integration tests for Modal provider with real API calls."""
    
    @pytest.fixture
    def modal_provider(self, modal_token_id, modal_token_secret):
        """Create Modal provider with real credentials."""
        if not modal_token_id or not modal_token_secret:
            pytest.skip("MODAL_TOKEN_ID and MODAL_TOKEN_SECRET not provided")
        
        return ModalProvider(token_id=modal_token_id, token_secret=modal_token_secret)
    
    @pytest.fixture
    def modal_config(self):
        """Create configuration for Modal testing."""
        return SandboxConfig(
            timeout=120,  # Modal might need more time for cold starts
            working_directory="/workspace",
            auto_cleanup=True
        )
    
    async def test_modal_provider_create_session(self, modal_provider, modal_config):
        """Test creating a real Modal session."""
        session = await modal_provider.create_session(modal_config)
        
        assert session is not None
        assert session.session_id is not None
        assert len(session.session_id) > 0
        
        await session.cleanup()
    
    async def test_modal_sandbox_basic_execution(self, modal_provider, modal_config):
        """Test basic command execution in Modal sandbox."""
        async with Sandbox(provider=modal_provider, config=modal_config) as sandbox:
            # Test simple echo command
            result = await sandbox.execute("echo 'Hello, Modal!'")
            
            assert isinstance(result, ExecutionResult)
            assert result.success
            assert result.return_code == 0
            assert "Hello, Modal!" in result.stdout
            assert result.execution_time > 0
    
    async def test_modal_sandbox_python_execution(self, modal_provider, modal_config):
        """Test Python code execution in Modal sandbox."""
        async with Sandbox(provider=modal_provider, config=modal_config) as sandbox:
            # Test Python execution
            python_code = "print('Python works in Modal!'); import sys; print(f'Python version: {sys.version}')"
            result = await sandbox.execute(f"python3 -c \"{python_code}\"")
            
            assert result.success
            assert "Python works in Modal!" in result.stdout
            assert "Python version:" in result.stdout
    
    async def test_modal_sandbox_file_operations(self, modal_provider, modal_config):
        """Test file upload/download operations in Modal sandbox."""
        async with Sandbox(provider=modal_provider, config=modal_config) as sandbox:
            # Upload a text file
            content = "This is a test file for Modal integration testing."
            await sandbox.upload_file("test.txt", content)
            
            # Verify file exists by listing
            files = await sandbox.list_files("/")
            file_names = [f.name for f in files]
            assert "test.txt" in file_names
            
            # Download and verify content
            downloaded_content = await sandbox.download_file("test.txt")
            assert downloaded_content.decode() == content
            
            # Test Python file execution
            python_script = """
print("Hello from Python file in Modal!")
with open("output.txt", "w") as f:
    f.write("Generated by Python script")
print("File created successfully")
"""
            await sandbox.upload_file("script.py", python_script)
            result = await sandbox.execute("python3 script.py")
            assert result.success
            assert "Hello from Python file in Modal!" in result.stdout
            assert "File created successfully" in result.stdout
            
            # Verify the output file was created
            output_content = await sandbox.download_file("output.txt")
            assert b"Generated by Python script" in output_content
    
    async def test_modal_sandbox_package_installation(self, modal_provider, modal_config):
        """Test package installation in Modal sandbox."""
        async with Sandbox(provider=modal_provider, config=modal_config) as sandbox:
            # Install a lightweight package
            result = await sandbox.execute("pip install requests")
            assert result.success or "already satisfied" in result.stdout.lower()
            
            # Test the installed package
            test_code = """
try:
    import requests
    print("Requests imported successfully!")
    print("Requests version:", requests.__version__)
    
    # Test a simple request (if internet is available)
    try:
        response = requests.get("https://httpbin.org/json", timeout=5)
        if response.status_code == 200:
            print("HTTP request successful!")
        else:
            print(f"HTTP request returned status: {response.status_code}")
    except Exception as e:
        print(f"HTTP request failed (expected in sandbox): {e}")
        
except ImportError as e:
    print(f"Failed to import requests: {e}")
"""
            await sandbox.upload_file("test_requests.py", test_code)
            result = await sandbox.execute("python3 test_requests.py")
            
            assert result.success
            assert "Requests imported successfully!" in result.stdout
    
    async def test_modal_sandbox_working_directory(self, modal_provider, modal_config):
        """Test working directory operations in Modal sandbox."""
        async with Sandbox(provider=modal_provider, config=modal_config) as sandbox:
            # Check current directory
            result = await sandbox.execute("pwd")
            assert result.success
            
            # Create and navigate to subdirectory
            await sandbox.execute("mkdir -p /tmp/subdir")
            result = await sandbox.execute("pwd", working_dir="/tmp/subdir")
            assert result.success
            
            # Test file operations in subdirectory
            await sandbox.upload_file("subdir/subfile.txt", "Content in subdirectory")
            files = await sandbox.list_files("/")
            # Note: Modal provider might handle file paths differently
            # This test verifies the interface works
    
    async def test_modal_sandbox_error_handling(self, modal_provider, modal_config):
        """Test error handling in Modal sandbox."""
        async with Sandbox(provider=modal_provider, config=modal_config) as sandbox:
            # Test command that fails
            result = await sandbox.execute("nonexistent_command_12345")
            
            assert not result.success
            assert result.return_code != 0
            
            # Test downloading non-existent file
            with pytest.raises(FileNotFoundError):
                await sandbox.download_file("nonexistent_file.txt")
    
    async def test_modal_sandbox_timeout_handling(self, modal_provider):
        """Test timeout handling in Modal sandbox."""
        config = SandboxConfig(timeout=10)  # Short timeout
        
        async with Sandbox(provider=modal_provider, config=config) as sandbox:
            # Test command with custom timeout
            result = await sandbox.execute("echo 'quick command'", timeout=5)
            assert result.success
            
            # Test longer running command
            result = await sandbox.execute("sleep 2 && echo 'completed'", timeout=5)
            assert result.success
            assert "completed" in result.stdout
    
    async def test_modal_sandbox_concurrent_operations(self, modal_provider, modal_config):
        """Test concurrent operations in Modal sandbox."""
        import asyncio
        
        async with Sandbox(provider=modal_provider, config=modal_config) as sandbox:
            # Run multiple commands concurrently
            tasks = [
                sandbox.execute(f"echo 'Modal Task {i}'")
                for i in range(3)
            ]
            
            results = await asyncio.gather(*tasks)
            
            assert len(results) == 3
            for i, result in enumerate(results):
                assert result.success
                assert f"Modal Task {i}" in result.stdout
    
    async def test_modal_sandbox_data_processing(self, modal_provider, modal_config):
        """Test data processing capabilities in Modal sandbox."""
        async with Sandbox(provider=modal_provider, config=modal_config) as sandbox:
            # Create a data processing script
            data_script = """
import json
import csv
from io import StringIO

# Sample data
data = [
    {"name": "Alice", "age": 25, "city": "New York"},
    {"name": "Bob", "age": 30, "city": "San Francisco"},
    {"name": "Charlie", "age": 35, "city": "Chicago"}
]

# Process data
print("Processing data...")
total_age = sum(person["age"] for person in data)
avg_age = total_age / len(data)

print(f"Total people: {len(data)}")
print(f"Average age: {avg_age:.1f}")

# Save as JSON
with open("data.json", "w") as f:
    json.dump(data, f, indent=2)

# Save as CSV
with open("data.csv", "w", newline="") as f:
    writer = csv.DictWriter(f, fieldnames=["name", "age", "city"])
    writer.writeheader()
    writer.writerows(data)

print("Data saved to data.json and data.csv")
"""
            
            await sandbox.upload_file("process_data.py", data_script)
            
            # Run the data processing
            result = await sandbox.execute("python3 process_data.py")
            assert result.success
            assert "Processing data..." in result.stdout
            assert "Total people: 3" in result.stdout
            assert "Average age: 30.0" in result.stdout
            assert "Data saved" in result.stdout
            
            # Verify output files were created
            files = await sandbox.list_files("/")
            file_names = [f.name for f in files]
            assert "data.json" in file_names
            assert "data.csv" in file_names
            
            # Download and verify JSON content
            json_content = await sandbox.download_file("data.json")
            assert b"Alice" in json_content
            assert b"New York" in json_content
    
    async def test_modal_sandbox_environment_variables(self, modal_provider):
        """Test environment variables in Modal sandbox."""
        config = SandboxConfig(
            environment_vars={"TEST_VAR": "modal_test_value", "CUSTOM_PATH": "/custom/path"}
        )
        
        async with Sandbox(provider=modal_provider, config=config) as sandbox:
            # Test environment variable access
            result = await sandbox.execute("echo $TEST_VAR")
            assert result.success
            # Note: Modal might not support custom environment variables in the same way
            # This test verifies the interface works
    
    async def test_modal_provider_multiple_sessions(self, modal_provider, modal_config):
        """Test creating multiple Modal sessions."""
        sessions = []
        
        try:
            # Create multiple sessions
            for i in range(2):
                session = await modal_provider.create_session(modal_config)
                sessions.append(session)
                
                # Test each session independently
                result = await session.execute(f"echo 'Modal Session {i}'")
                assert result.success
                assert f"Modal Session {i}" in result.stdout
        
        finally:
            # Clean up all sessions
            for session in sessions:
                await session.cleanup()
    
    async def test_modal_provider_session_isolation(self, modal_provider, modal_config):
        """Test that Modal sessions are properly isolated."""
        # Create first session and add a file
        session1 = await modal_provider.create_session(modal_config)
        try:
            await session1.upload_file("session1_file.txt", "Session 1 content")
            
            # Create second session
            session2 = await modal_provider.create_session(modal_config)
            try:
                # Verify second session doesn't see first session's files
                files = await session2.list_files("/")
                file_names = [f.name for f in files]
                assert "session1_file.txt" not in file_names
                
                # Add file to second session
                await session2.upload_file("session2_file.txt", "Session 2 content")
                
                # Verify first session doesn't see second session's files
                files = await session1.list_files("/")
                file_names = [f.name for f in files]
                assert "session2_file.txt" not in file_names
                assert "session1_file.txt" in file_names
            
            finally:
                await session2.cleanup()
        
        finally:
            await session1.cleanup()
    
    @pytest.mark.slow
    async def test_modal_sandbox_machine_learning_workflow(self, modal_provider, modal_config):
        """Test a machine learning workflow in Modal sandbox."""
        async with Sandbox(provider=modal_provider, config=modal_config) as sandbox:
            # Install required packages
            result = await sandbox.execute("pip install scikit-learn numpy")
            assert result.success or "already satisfied" in result.stdout.lower()
            
            # Create a simple ML script
            ml_script = """
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import json

print("Starting ML workflow...")

# Generate sample data
np.random.seed(42)
X = np.random.randn(100, 1)
y = 2 * X.flatten() + 1 + np.random.randn(100) * 0.1

print(f"Generated {len(X)} data points")

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)

print(f"Model trained successfully!")
print(f"Coefficient: {model.coef_[0]:.3f}")
print(f"Intercept: {model.intercept_:.3f}")
print(f"Test MSE: {mse:.6f}")

# Save results
results = {
    "coefficient": float(model.coef_[0]),
    "intercept": float(model.intercept_),
    "test_mse": float(mse),
    "data_points": len(X)
}

with open("ml_results.json", "w") as f:
    json.dump(results, f, indent=2)

print("Results saved to ml_results.json")
"""
            
            await sandbox.upload_file("ml_workflow.py", ml_script)
            
            # Run the ML workflow
            result = await sandbox.execute("python3 ml_workflow.py")
            assert result.success
            assert "Starting ML workflow..." in result.stdout
            assert "Model trained successfully!" in result.stdout
            assert "Results saved" in result.stdout
            
            # Verify results file was created
            files = await sandbox.list_files("/")
            file_names = [f.name for f in files]
            assert "ml_results.json" in file_names
            
            # Download and verify the results
            results_content = await sandbox.download_file("ml_results.json")
            assert b"coefficient" in results_content
            assert b"test_mse" in results_content


@pytest.mark.integration
@pytest.mark.modal
class TestModalProviderErrorScenarios:
    """Test error scenarios with Modal provider."""
    
    async def test_modal_invalid_credentials(self):
        """Test Modal provider with invalid credentials."""
        provider = ModalProvider(token_id="invalid_id", token_secret="invalid_secret")
        config = SandboxConfig()
        
        # Should fail when trying to create session
        with pytest.raises(Exception):  # Could be AuthenticationError or ProviderError
            await provider.create_session(config)
    
    async def test_modal_missing_credentials(self):
        """Test Modal provider without credentials."""
        # Clear environment variables
        with pytest.MonkeyPatch().context() as m:
            m.delenv("MODAL_TOKEN_ID", raising=False)
            m.delenv("MODAL_TOKEN_SECRET", raising=False)
            
            with pytest.raises(AuthenticationError):
                ModalProvider()
    
    async def test_modal_partial_credentials(self):
        """Test Modal provider with only partial credentials."""
        # Test with only token_id
        with pytest.raises(AuthenticationError):
            ModalProvider(token_id="test_id")
        
        # Test with only token_secret
        with pytest.raises(AuthenticationError):
            ModalProvider(token_secret="test_secret")
    
    async def test_modal_provider_cleanup_with_active_sessions(self, modal_token_id, modal_token_secret):
        """Test Modal provider cleanup with active sessions."""
        if not modal_token_id or not modal_token_secret:
            pytest.skip("Modal credentials not provided")
        
        provider = ModalProvider(token_id=modal_token_id, token_secret=modal_token_secret)
        config = SandboxConfig()
        
        # Create a session
        session = await provider.create_session(config)
        
        # Cleanup provider (should cleanup session too)
        await provider.cleanup()
        
        # Session should be cleaned up
        # Note: Specific behavior depends on Modal implementation

